{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "sDNDfUHoDYaX",
        "outputId": "daaf8018-24a5-47d5-baf3-a1d738e66bf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorflow-io-gcs-filesystem, tensorboard-data-server, google-pasta, tensorboard, astunparse, tensorflow\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 google-pasta-0.2.0 libclang-18.1.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 werkzeug-3.1.3 wheel-0.45.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2\n",
        "# Define activation functions to search\n",
        "# Importing necessary libraries\n",
        "import kagglehub\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras import regularizers, optimizers\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "\n",
        "#Required for the notebook's reproduciiility\n",
        "np.random.seed(2)\n",
        "tf.random.set_seed(2)\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"muhammadtahir194/movies-dataset-tmdb-top-rated\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "file_path=\"\"\n",
        "for file in os.listdir(path):\n",
        "    if file.endswith(\".csv\"):\n",
        "        file_path = os.path.join(path, file)\n",
        "        break\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head())\n",
        "df.dropna(inplace=True)\n",
        "df['is_popular'] = df['popularity'] > 4.0\n",
        "df['is_popular'] = df['is_popular'].astype(int) #form of one-hot encodinng\n",
        "\n",
        "# Convert the release_date column to datetime format and extracting only the year\n",
        "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
        "df['release_year'] = df['release_date'].dt.year.astype(int)\n",
        "df.drop(columns=['release_date'], inplace=True)\n",
        "\n",
        "df.drop(columns=['title', 'overview'], inplace=True)\n",
        "print(df.head())\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X, y = df.drop(columns=['id','popularity', 'is_popular']), df['is_popular']\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "\n",
        "stratify_val = y if len(np.unique(y)) < 20 else None\n",
        "print(\"Unique y values in the dataset: \", len(np.unique(y)))\n",
        "\n",
        "# Splitting data into training (70%), validation (15%), and test (15%) sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=2, stratify=stratify_val)\n",
        "stratify_val_temp = y_temp if stratify_val is not None else None\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=2, stratify=stratify_val_temp)\n",
        "\n",
        "print(f\"Training Set: {X_train.shape}, Validation Set: {X_val.shape}, Test Set: {X_test.shape}\")\n",
        "\n",
        "# Scaling the numerical features\n",
        "numerical_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
        "scaler = StandardScaler()\n",
        "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
        "X_val[numerical_cols] = scaler.transform(X_val[numerical_cols])\n",
        "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "de0eWiZaDDKH",
        "outputId": "4c941c9a-d435-40a5-ced4-5e87ce8008fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/movies-dataset-tmdb-top-rated\n",
            "        id                     title  \\\n",
            "0      278  The Shawshank Redemption   \n",
            "1      238             The Godfather   \n",
            "2      240     The Godfather Part II   \n",
            "3      424          Schindler's List   \n",
            "4  1356039             Counterattack   \n",
            "\n",
            "                                            overview release_date  popularity  \\\n",
            "0  Imprisoned in the 1940s for the double murder ...   1994-09-23       5.522   \n",
            "1  Spanning the years 1945 to 1955, a chronicle o...   1972-03-14       5.317   \n",
            "2  In the continuing saga of the Corleone crime f...   1974-12-20       4.747   \n",
            "3  The true story of how businessman Oskar Schind...   1993-12-15       4.457   \n",
            "4  When a hostage rescue mission creates a new en...   2025-02-27       9.430   \n",
            "\n",
            "   vote_average  vote_count  \n",
            "0         8.708       27883  \n",
            "1         8.689       21151  \n",
            "2         8.570       12771  \n",
            "3         8.567       16219  \n",
            "4         8.524         431  \n",
            "        id  popularity  vote_average  vote_count  is_popular  release_year\n",
            "0      278       5.522         8.708       27883           1          1994\n",
            "1      238       5.317         8.689       21151           1          1972\n",
            "2      240       4.747         8.570       12771           1          1974\n",
            "3      424       4.457         8.567       16219           1          1993\n",
            "4  1356039       9.430         8.524         431           1          2025\n",
            "X shape: (8558, 3)\n",
            "y shape: (8558,)\n",
            "Unique y values in the dataset:  2\n",
            "Training Set: (5990, 3), Validation Set: (1284, 3), Test Set: (1284, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_tuner"
      ],
      "metadata": {
        "id": "h12R74BaD4Km",
        "outputId": "f555ed1f-089e-497b-a156-69050ab1bd6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras_tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras_tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras_tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras_tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras_tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras_tuner) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras_tuner\n",
            "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "\n",
        "ACTIVATION_FUNCTIONS = ['relu', 'tanh', 'sigmoid', 'elu', 'leaky_relu']\n",
        "\n",
        "def build_model(hp):\n",
        "    neurons = hp.Int('neurons', min_value=8, max_value=512, step=8)\n",
        "    layers = hp.Int('layers', min_value=2, max_value=6, step=1)\n",
        "    dropout_rate = hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)\n",
        "    learning_rate = hp.Choice('learning_rate', values=[0.001, 0.0005, 0.0001])\n",
        "    optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])\n",
        "    activation_list = [hp.Choice(f'activation_{i}', values=ACTIVATION_FUNCTIONS) for i in range(layers)]\n",
        "    batch_norm = hp.Boolean('batch_norm')\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # First layer\n",
        "    if activation_list[0] == 'leaky_relu':\n",
        "        model.add(Dense(neurons, input_shape=(X_train.shape[1],)))\n",
        "        model.add(LeakyReLU(alpha=0.01))\n",
        "    else:\n",
        "        model.add(Dense(neurons, activation=activation_list[0], input_shape=(X_train.shape[1],)))\n",
        "\n",
        "    if batch_norm:\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Hidden layers\n",
        "    for i in range(1, layers):\n",
        "        model.add(Dense(neurons))\n",
        "        if activation_list[i] == 'leaky_relu':\n",
        "            model.add(LeakyReLU(alpha=0.01))\n",
        "        else:\n",
        "            model.add(Dense(neurons, activation=activation_list[i]))\n",
        "\n",
        "        if batch_norm:\n",
        "            model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Optimizer selection\n",
        "    if optimizer == 'adam':\n",
        "        optimizer = Adam(learning_rate)\n",
        "    elif optimizer == 'rmsprop':\n",
        "        optimizer = RMSprop(learning_rate)\n",
        "    else:\n",
        "        optimizer = SGD(learning_rate)\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Custom tuner to prioritize test accuracy\n",
        "class CustomTuner(kt.Hyperband):\n",
        "    def __init__(self, *args, X_test, y_test, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "        self.test_scores = {}\n",
        "\n",
        "    def on_trial_end(self, trial):\n",
        "        \"\"\"Override method to evaluate test accuracy.\"\"\"\n",
        "        model = self.load_model(trial)  # Use trial as an argument\n",
        "        _, test_acc = model.evaluate(self.X_test, self.y_test, verbose=0)\n",
        "        self.test_scores[trial.trial_id] = test_acc\n",
        "        super().on_trial_end(trial)\n",
        "\n",
        "    def get_best_trial(self):\n",
        "        \"\"\"Find the best trial based on test accuracy first, then validation accuracy.\"\"\"\n",
        "        trials_list = list(self.oracle.trials.values())  # Get trials from the oracle\n",
        "        sorted_trials = sorted(\n",
        "            trials_list,\n",
        "            key=lambda trial: (-self.test_scores.get(trial.trial_id, 0), -trial.score),\n",
        "        )\n",
        "        return sorted_trials[0] if sorted_trials else None\n",
        "\n",
        "    def get_best_model(self):\n",
        "        \"\"\"Return the best model based on the best trial.\"\"\"\n",
        "        best_trial = self.get_best_trial()\n",
        "        return self.load_model(best_trial) if best_trial else None\n",
        "\n",
        "\n",
        "# Initialize the custom tuner\n",
        "tuner = CustomTuner(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=50,\n",
        "    factor=3,\n",
        "    directory='my_tuner_dir',\n",
        "    project_name='movie_popularity',\n",
        "    X_test=X_test,  # Pass test data\n",
        "    y_test=y_test\n",
        ")\n",
        "\n",
        "def tuner_search():\n",
        "    # Perform hyperparameter search\n",
        "    tuner.search(X_train, y_train, epochs=50, validation_data=(X_val, y_val), batch_size=16)\n",
        "\n",
        "    # Get the best hyperparameters\n",
        "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "    print(\"Best Hyperparameters:\", best_hps.values)\n",
        "\n",
        "    # Get the best model based on test accuracy\n",
        "    best_model = tuner.get_best_model()\n",
        "\n",
        "    # Evaluate the best model\n",
        "    test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "    print(f\"Best Model Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    # Return the best model\n",
        "    return best_model, best_hps.values, test_acc\n",
        "\n",
        "keras_model, keras_model_arams, keras_model_test_acc = tuner_search()\n"
      ],
      "metadata": {
        "id": "6cL2sQiRC1nG",
        "outputId": "6b493d87-4b47-4b80-ae33-f4590eb24479",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 01m 10s]\n",
            "val_accuracy: 0.8940809965133667\n",
            "\n",
            "Best val_accuracy So Far: 0.9034267663955688\n",
            "Total elapsed time: 00h 45m 32s\n",
            "Best Hyperparameters: {'neurons': 472, 'layers': 2, 'dropout_rate': 0.5, 'learning_rate': 0.001, 'optimizer': 'rmsprop', 'activation_0': 'leaky_relu', 'activation_1': 'relu', 'batch_norm': False, 'activation_2': 'leaky_relu', 'activation_3': 'elu', 'activation_4': 'tanh', 'activation_5': 'tanh', 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '0046'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 26 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8835 - loss: 0.2888\n",
            "Best Model Test Accuracy: 0.8847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xv5228c-D2RI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Witamy w Colaboratory",
      "toc_visible": true,
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}